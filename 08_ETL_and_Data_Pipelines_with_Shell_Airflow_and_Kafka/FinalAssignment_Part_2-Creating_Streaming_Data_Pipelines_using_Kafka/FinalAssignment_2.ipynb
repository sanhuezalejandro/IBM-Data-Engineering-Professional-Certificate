{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final Assignment (Part 2) - Creating Streaming Data Pipelines using Kafka**\n",
    "\n",
    "# **Scenario**\n",
    "\n",
    "You are a data engineer at a data analytics consulting company. You have been assigned to a project that aims to de-congest the national highways by analyzing the road traffic data from different toll plazas. As a vehicle passes a toll plaza, the vehicle’s data like `vehicle_id`,`vehicle_type`,`toll_plaza_id` and timestamp are streamed to Kafka. Your job is to create a data pipe line that collects the streaming data and loads it into a database.\n",
    "\n",
    "## **Objectives**\n",
    "\n",
    "In this assignment you will create a streaming data pipe by performing these steps:\n",
    "\n",
    "- Start a MySQL Database server.\n",
    "- Create a table to hold the toll data.\n",
    "- Start the Kafka server.\n",
    "- Install the Kafka python driver.\n",
    "- Install the MySQL python driver.\n",
    "- Create a topic named toll in kafka.\n",
    "- Download streaming data generator program.\n",
    "- Customize the generator program to steam to toll topic.\n",
    "- Download and customise streaming data consumer.\n",
    "- Customize the consumer program to write into a MySQL database table.\n",
    "- Verify that streamed data is being collected in the database table.\n",
    "\n",
    "# **Exercise 1 - Prepare the lab environment**\n",
    "\n",
    "Before you start the assignment, complete the following steps to set up the lab:\n",
    "\n",
    "- Step 1: Download Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 68.2M  100 68.2M    0     0  4303k      0  0:00:16  0:00:16 --:--:-- 9961k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://archive.apache.org/dist/kafka/2.8.0/kafka_2.12-2.8.0.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  113M  100  113M    0     0  4811k      0  0:00:24  0:00:24 --:--:-- 10.7M\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://archive.apache.org/dist/kafka/3.7.0/kafka_2.13-3.7.0.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Extract Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf kafka_2.12-2.8.0.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf kafka_2.13-3.7.0.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Start MySQL server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener la contraseña de la variable de entorno\n",
    "password = os.getenv(\"DB_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/usr/local/mysql-8.0.31-macos12-arm64/bin/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Create a database named tolldata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{path}mysql --host=127.0.0.1 --port=3306 --user=root --password={password} --execute=\"CREATE DATABASE tolldata\" 2>/dev/null;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| Database           |\n",
      "+--------------------+\n",
      "| employees          |\n",
      "| information_schema |\n",
      "| mysql              |\n",
      "| performance_schema |\n",
      "| sakila             |\n",
      "| sys                |\n",
      "| tolldata           |\n",
      "| world              |\n",
      "+--------------------+\n"
     ]
    }
   ],
   "source": [
    "!{path}mysql --host=127.0.0.1 --port=3306 --user=root --password={password} --execute=\"SHOW DATABASES\" 2>/dev/null;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la URL de conexión\n",
    "%sql mysql+pymysql://root:{password}@localhost:3306/tolldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/tolldata\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Tables_in_tolldata</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SHOW TABLES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/tolldata\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql create table livetolldata(timestamp datetime,vehicle_id int,vehicle_type char(15),toll_plaza_id smallint);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/tolldata\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Tables_in_tolldata</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>livetolldata</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('livetolldata',)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SHOW TABLES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Install the python module kafka-python using the pip command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka-python\n",
      "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl.metadata (7.8 kB)\n",
      "Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: kafka-python\n",
      "Successfully installed kafka-python-2.0.2\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Install the python module mysql-connector-python using the pip command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python==8.0.31\n",
      "  Downloading mysql_connector_python-8.0.31-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.8 kB)\n",
      "Collecting protobuf<=3.20.1,>=3.11.0 (from mysql-connector-python==8.0.31)\n",
      "  Downloading protobuf-3.20.1-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Downloading mysql_connector_python-8.0.31-cp39-cp39-macosx_11_0_arm64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading protobuf-3.20.1-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: protobuf, mysql-connector-python\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "      Successfully uninstalled protobuf-4.21.12\n",
      "  Attempting uninstall: mysql-connector-python\n",
      "    Found existing installation: mysql-connector-python 8.1.0\n",
      "    Uninstalling mysql-connector-python-8.1.0:\n",
      "      Successfully uninstalled mysql-connector-python-8.1.0\n",
      "Successfully installed mysql-connector-python-8.0.31 protobuf-3.20.1\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install mysql-connector-python==8.0.31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 2 - Start Kafka**\n",
    "\n",
    "### **Task 2.1 - Start Zookeeper**\n",
    "\n",
    "Start zookeeper server.\n",
    "\n",
    "Take a screenshot of the command you run.\n",
    "\n",
    "Name the screenshot `start_zookeeper.jpg`. (Images can be saved with either the .jpg or .png extension.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2.2 - Start Kafka server**\n",
    "\n",
    "Start Kafka server\n",
    "\n",
    "Take a screenshot of the command you run.\n",
    "\n",
    "Name the screenshot `start_kafka.jpg`. (Images can be saved with either the .jpg or .png extension.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CREATE DOCKER-COMPOSE.YML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version: '2'\n",
    "\n",
    "# services:\n",
    "#   zookeeper:\n",
    "#     image: arm64v8/zookeeper\n",
    "#     ports:\n",
    "#       - \"2181:2181\"\n",
    "\n",
    "#   kafka:\n",
    "#     image: bitnami/kafka:latest\n",
    "#     ports:\n",
    "#       - \"9092:9092\"\n",
    "#     expose:\n",
    "#       - \"9093\"\n",
    "#     environment:\n",
    "#       KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092\n",
    "#       KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT\n",
    "#       KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092\n",
    "#       KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE\n",
    "#       KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n",
    "#       KAFKA_CREATE_TOPICS: \"my-topic:1:1\"\n",
    "#     depends_on:\n",
    "#       - zookeeper\n",
    "#     volumes:\n",
    "#       - /var/run/docker.sock:/var/run/docker.sock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2.3 - Create a topic named toll**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docker exec -it <kafka-container-id> /opt/bitnami/kafka/bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic my-topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2.4 - Download the Toll Traffic Simulator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   828  100   828    0     0   1071      0 --:--:-- --:--:-- --:--:--  1085\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Final%20Assignment/toll_traffic_generator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2.5 - Configure the Toll Traffic Simulator**\n",
    "\n",
    "Open the `toll_traffic_generator.py` and set the topic to `toll`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2.6 - Run the Toll Traffic Simulator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python3 toll_traffic_generator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2.7 - Configure streaming_data_reader.py**\n",
    "\n",
    "Download the `streaming_data_reader.py` from the url below using ‘wget’\n",
    "\n",
    "`https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Final%20Assignment/streaming_data_reader.py`\n",
    "\n",
    "Open the `streaming_data_reader.py` and modify the following details so that the program can connect to your mysql server.\n",
    "\n",
    "`TOPIC`\n",
    "\n",
    "`DATABASE`\n",
    "\n",
    "`USERNAME`\n",
    "\n",
    "`PASSWORD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1364  100  1364    0     0   1410      0 --:--:-- --:--:-- --:--:--  1515\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Final%20Assignment/streaming_data_reader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2.8 - Run streaming_data_reader.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python3 streaming_data_reader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 2.9 - Health check of the streaming data pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/tolldata\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>timestamp</th>\n",
       "            <th>vehicle_id</th>\n",
       "            <th>vehicle_type</th>\n",
       "            <th>toll_plaza_id</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2024-05-04 01:22:05</td>\n",
       "            <td>5809462</td>\n",
       "            <td>car</td>\n",
       "            <td>4007</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2024-05-04 01:22:07</td>\n",
       "            <td>7842899</td>\n",
       "            <td>truck</td>\n",
       "            <td>4004</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2024-05-04 01:22:08</td>\n",
       "            <td>2078344</td>\n",
       "            <td>car</td>\n",
       "            <td>4001</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2024-05-04 01:22:09</td>\n",
       "            <td>8338187</td>\n",
       "            <td>car</td>\n",
       "            <td>4010</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2024-05-04 01:22:10</td>\n",
       "            <td>1096077</td>\n",
       "            <td>car</td>\n",
       "            <td>4001</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2024-05-04 01:22:10</td>\n",
       "            <td>5138689</td>\n",
       "            <td>car</td>\n",
       "            <td>4005</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2024-05-04 01:22:11</td>\n",
       "            <td>8376169</td>\n",
       "            <td>car</td>\n",
       "            <td>4001</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2024-05-04 01:22:11</td>\n",
       "            <td>6546105</td>\n",
       "            <td>truck</td>\n",
       "            <td>4002</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2024-05-04 01:22:12</td>\n",
       "            <td>9569143</td>\n",
       "            <td>truck</td>\n",
       "            <td>4001</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2024-05-04 01:22:12</td>\n",
       "            <td>6540270</td>\n",
       "            <td>van</td>\n",
       "            <td>4010</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.datetime(2024, 5, 4, 1, 22, 5), 5809462, 'car', 4007),\n",
       " (datetime.datetime(2024, 5, 4, 1, 22, 7), 7842899, 'truck', 4004),\n",
       " (datetime.datetime(2024, 5, 4, 1, 22, 8), 2078344, 'car', 4001),\n",
       " (datetime.datetime(2024, 5, 4, 1, 22, 9), 8338187, 'car', 4010),\n",
       " (datetime.datetime(2024, 5, 4, 1, 22, 10), 1096077, 'car', 4001),\n",
       " (datetime.datetime(2024, 5, 4, 1, 22, 10), 5138689, 'car', 4005),\n",
       " (datetime.datetime(2024, 5, 4, 1, 22, 11), 8376169, 'car', 4001),\n",
       " (datetime.datetime(2024, 5, 4, 1, 22, 11), 6546105, 'truck', 4002),\n",
       " (datetime.datetime(2024, 5, 4, 1, 22, 12), 9569143, 'truck', 4001),\n",
       " (datetime.datetime(2024, 5, 4, 1, 22, 12), 6540270, 'van', 4010)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM livetolldata LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/tolldata\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>COUNT(*)</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>54</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(54,)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT COUNT(*) FROM livetolldata "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
