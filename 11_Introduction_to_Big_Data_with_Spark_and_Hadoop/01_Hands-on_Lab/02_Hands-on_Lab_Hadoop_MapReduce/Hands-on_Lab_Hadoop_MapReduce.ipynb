{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5d436e",
   "metadata": {},
   "source": [
    "# Hands-on Lab: Hadoop MapReduce\n",
    "\n",
    "![https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/images/IDSN-logo.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/images/IDSN-logo.png)\n",
    "\n",
    "### **Objectives**\n",
    "\n",
    "- Run a single-node Hadoop instance\n",
    "- Perform a word count using Hadoop **Map Reduce**.\n",
    "\n",
    "[https://www.coursera.org/learn/introduction-to-big-data-with-spark-hadoop/ungradedLti/OKW00/hands-on-lab-hadoop-mapreduce](https://www.coursera.org/learn/introduction-to-big-data-with-spark-hadoop/ungradedLti/OKW00/hands-on-lab-hadoop-mapreduce)\n",
    "\n",
    "# **Set up Single-Node Hadoop**\n",
    "\n",
    "The steps outlined in this lab use the single-node Hadoop Version 3.3.6 **Hadoop** is most useful when deployed in a fully distributed mode on a large cluster of networked servers sharing a large volume of data. However, for basic understanding, we will configure Hadoop on a single node.\n",
    "\n",
    "In this lab, we will run the WordCount example with an input text and see how the content of the input file is processed by WordCount.\n",
    "\n",
    "1. Start a new terminal\n",
    "\n",
    "![https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/images/New_terminal.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/images/New_terminal.png)\n",
    "\n",
    "1. Download hadoop-3.2.3.tar.gz to your theia environment by running the following command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e244a6a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "curl https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz --output hadoop-3.3.6.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1446c7d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Extract the tar file in the currently directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "279cd1fd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "tar -xvf hadoop-3.3.6.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e694a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Navigate to the hadoop-3.3.6 directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e20c930",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "cd hadoop-3.3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6840430",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Check the hadoop command to see if it is setup. This will display the usage documentation for the hadoop script.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ea7301b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "bin/hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8edaa8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Run the following command to download data.txt to your current directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "129fb509",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "curl https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/data.txt --output data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080593d3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Run the Map reduce application for wordcount on data.txt and store the output in **/user/root/output**\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d18279c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar wordcount data.txt output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2783b9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> This may take some time.\n",
    ">\n",
    "1. Once the word count runs successfully, you can run the following command to see the output file it has generated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f874c842",
   "metadata": {},
   "source": [
    "ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dbf675",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You should see **part-r-00000** with **_SUCCESS** indicating that the wordcount has been done.\n",
    "\n",
    "> While it is still processing, you may only see ‘_temporary’ listed in the output directory. Wait for a couple of minutes and run the command again till you see output as shown above.\n",
    ">\n",
    "1. Run the following command to see the word count output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48ae80b3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "cat  output/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acdd3aa",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/images/wordcount_output.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/images/wordcount_output.png)\n",
    "\n",
    "The image below shows how the MapReduce wordcount happens.\n",
    "\n",
    "![https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/images/map_reduce_picture_rep.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/images/map_reduce_picture_rep.png)\n",
    "\n",
    "# **Practice Lab**\n",
    "\n",
    "1. Do a word count on a file with the following content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67e82583",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "Italy Venice\n",
    "Italy Pizza\n",
    "Pizza Pasta Gelato\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b3aeb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Click here for a hint on how to get started\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9916235",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "rm data.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f328147e",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af7078a3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "rm -rf output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cd680e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Click here for hint on how to create a file to wordcount\n",
    "\n",
    "Create data.txt with the required content. You may either use the file editor.\n",
    "\n",
    "- Click here for solution on how to do word count on the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b596e97d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar wordcount data.txt output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0841981e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Click here for sample output\n",
    "\n",
    "The output will be as below.\n",
    "\n",
    "![https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/images/practice_lab_output.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/images/practice_lab_output.png)\n",
    "\n",
    "# **Congratulations! You have:**\n",
    "\n",
    "- Deployed Hadoop using Docker\n",
    "- Copied data into HDFS\n",
    "- Used MapReduce to do a word count\n",
    "\n",
    "\n",
    "## **Author(s)**\n",
    "\n",
    "Lavanya T S\n",
    "\n",
    "## **Contributor(s)**\n",
    "\n",
    "[Aije Egwaikhide](https://www.linkedin.com/in/aije-egwaikhide/)\n",
    "\n",
    "### **© IBM Corporation. All rights reserved.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
