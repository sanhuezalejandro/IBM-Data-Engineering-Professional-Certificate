{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08710833",
   "metadata": {},
   "source": [
    "# Hands-on Lab: Getting Started with Hive\n",
    "\n",
    "[https://www.coursera.org/learn/introduction-to-big-data-with-spark-hadoop/ungradedLti/9tFRc/hands-on-lab-getting-started-with-hive](https://www.coursera.org/learn/introduction-to-big-data-with-spark-hadoop/ungradedLti/9tFRc/hands-on-lab-getting-started-with-hive)\n",
    "\n",
    "![https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/images/IDSN-logo.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/images/IDSN-logo.png)\n",
    "\n",
    "**Estimated time needed:** 20 minutes\n",
    "\n",
    "In this lab you will explore Apache Hive, a distributed, fault-tolerant data warehouse system that enables analytics at a massive scale. You will be creating a table and running SQL commands on it.\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "At the end of this lab, you will be able to:\n",
    "\n",
    "- Create a table in Hive\n",
    "- Add data to the table using file\n",
    "- Add data to the table using `insert`\n",
    "- Query the data in the table using SQL commands\n",
    "\n",
    "## **Prerequisites**\n",
    "\n",
    "- You should comfortable working with the Linux terminal\n",
    "- Prior knowledge of SQL will be helpful\n",
    "\n",
    "> While all the terminal commands can be copy pasted and run, it is highly recommended for you to type the commands for better learning.\n",
    ">\n",
    "\n",
    "# **Step 1: Get a copy of the CSV file**\n",
    "\n",
    "1. You will run the commands in the terminal. If you don’t have a terminal open, open a new terminal, by clicking on `Terminal` and choosing `New Terminal` from the submenu.\n",
    "\n",
    "![https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/images/New%20Terminal.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/images/New%20Terminal.png)\n",
    "\n",
    "1. Create a directory named `data` under `/home/project` by running the following command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87925058",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "mkdir /home/project/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459a073",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Change to the `/home/project/data` directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1390cca",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "cd /home/project/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d63a4d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Run the following command to get the `emp.csv`, a data file with Employee data, in a comma-separated file which you will use later to infuse data into the table you create.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f839448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   854  100   854    0     0    993      0 --:--:-- --:--:-- --:--:--   993:--:-- --:--:-- --:--:--     0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!curl -O https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/data/emp.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616e943",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Open the file in editor and view the file.\n",
    "\n",
    "![https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/images/view_empcsv.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/images/view_empcsv.png)\n",
    "\n",
    "# **Step 2: Setup Hive and Bee**\n",
    "\n",
    "1. You will use the hive from the docker hub for this lab. Pull the hive image into your system by running the following command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e97c93b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "docker pull apache/hive:4.0.0-alpha-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ba778",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> This will take a few seconds, depending on the speed of your internet connection.\n",
    ">\n",
    "1. Now, you will run the hive server on port `10002`. You will name the server instance `myhiveserver`. We will mount the local `data` folder in the hive server as `hive_custom_data`. This would mean that the whole `data` folder that you created locally, along with anything you add in the data folder, is copied into the container under the directory `hive_custom_data`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f50e8d57",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "docker run -d -p 10000:10000 -p 10002:10002 --env SERVICE_NAME=hiveserver2 -v /home/project/data:/hive_custom_data --name myhiveserver apache/hive:4.0.0-alpha-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00b03b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. You can open and take a look at the Hive server with the GUI. Click the button to open the HiveServer2 GUI.\n",
    "\n",
    "HiveServer2 GUI\n",
    "\n",
    "1. Now run the following command, which allows you to access `beeline`. This is a SQL cli where you can create, modify, delete table, and access data in the table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6cb81be2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "docker exec -it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b1d09",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **Step 3: Create table, add and view data**\n",
    "\n",
    "1. To create a new table `Employee` with three columns as in the csv you downloaded - em_id, emp_name and salary, run the following command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cff1d834",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "create table Employee(emp_id string, emp_name string, salary  int)  row format delimited fields terminated by ',' ;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f5a66",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> You may notice that there is an explicit mention for the fields delimited by , just as in the csv file.\n",
    ">\n",
    "1. Run the following command to check if the table is created.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "314e8703",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "show tables;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a1d2f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This should list the Employee table that you just created.\n",
    "\n",
    "1. Now load the data into the table from the csv file by running the following command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1cf5527",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "LOAD DATA INPATH '/hive_custom_data/emp.csv' INTO TABLE Employee;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3da8eb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Run the following command to list all the rows from the table to check if the data has been loaded from the CSV.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc5975cc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "SELECT * FROM employee;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ea54d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. You can view the details of the commands and the outcome in the HiveServer2 GUI.\n",
    "\n",
    "HiveServer2 GUI\n",
    "\n",
    "1. To quit from the beehive prompt in the terminal, press `ctrl+D`.\n",
    "\n",
    "Hive internally uses MapReduce to process and analyze data. When you execute a Hive query, it generates MapReduce jobs that run on the Hadoop cluster.\n",
    "\n",
    "# **Conclusion**\n",
    "\n",
    "In this lab you created a table in hive, added data to the table from csv and listed the data contained in the table.\n",
    "\n",
    "## **Next Steps**\n",
    "\n",
    "You can explore more SQL commands with table and see how it works.\n",
    "\n",
    "## **Author(s)**\n",
    "\n",
    "Lavanya T S\n",
    "\n",
    "### **© IBM Corporation. All rights reserved.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
